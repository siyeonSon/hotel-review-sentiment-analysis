{"cells":[{"cell_type":"markdown","source":["## 3) 주어진 호텔 리뷰 데이터를 가지고 할 수 있는 분석이 있으면 더 진행해보시오."],"metadata":{"id":"0qtEB0vc5fAB"}},{"cell_type":"code","source":["from string import punctuation\n","from tensorflow.keras.utils import to_categorical\n","import pandas as pd\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import CountVectorizer\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, Dense, LSTM, SimpleRNN\n","from google.colab import drive"],"metadata":{"id":"0aAuV8qv5lJa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OG-r9kUXi3wP"},"source":["### 자연어 생성\n","리뷰들을 'Hotel_reviews_20k.csv' 파일에서 가져온 후 RNN을 이용하여 모델을 학습 시킨 다음 좋은 리뷰와 나쁜 리뷰를 생성했다"]},{"cell_type":"code","source":["drive.mount('/content/drive')\n","\n","# CSV 파일을 pandas 데이터프레임으로 로드\n","df = pd.read_csv('Hotel_reviews_20k.csv', encoding='latin1')"],"metadata":{"id":"jRlgau1W5rtf"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bu3otVnZVbc3","outputId":"24ca7e55-6e33-45ce-f1a7-b715dd9eb0f4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","단어 집합의 크기 : 606\n","학습에 사용할 샘플의 개수: 1461\n","샘플의 최대 길이 : 635\n","Epoch 1/70\n","46/46 - 39s - loss: 6.3213 - accuracy: 0.0479 - 39s/epoch - 858ms/step\n","Epoch 2/70\n","46/46 - 34s - loss: 5.9185 - accuracy: 0.0657 - 34s/epoch - 742ms/step\n","Epoch 3/70\n","46/46 - 37s - loss: 5.7108 - accuracy: 0.0657 - 37s/epoch - 794ms/step\n","Epoch 4/70\n","46/46 - 32s - loss: 5.6812 - accuracy: 0.0657 - 32s/epoch - 706ms/step\n","Epoch 5/70\n","46/46 - 32s - loss: 5.6732 - accuracy: 0.0657 - 32s/epoch - 688ms/step\n","Epoch 6/70\n","46/46 - 31s - loss: 5.6690 - accuracy: 0.0657 - 31s/epoch - 677ms/step\n","Epoch 7/70\n","46/46 - 33s - loss: 5.6669 - accuracy: 0.0657 - 33s/epoch - 707ms/step\n","Epoch 8/70\n","46/46 - 33s - loss: 5.6644 - accuracy: 0.0657 - 33s/epoch - 712ms/step\n","Epoch 9/70\n","46/46 - 34s - loss: 5.6600 - accuracy: 0.0657 - 34s/epoch - 730ms/step\n","Epoch 10/70\n","46/46 - 31s - loss: 5.6513 - accuracy: 0.0657 - 31s/epoch - 684ms/step\n","Epoch 11/70\n","46/46 - 31s - loss: 5.6344 - accuracy: 0.0657 - 31s/epoch - 678ms/step\n","Epoch 12/70\n","46/46 - 31s - loss: 5.6079 - accuracy: 0.0657 - 31s/epoch - 684ms/step\n","Epoch 13/70\n","46/46 - 34s - loss: 5.5606 - accuracy: 0.0657 - 34s/epoch - 739ms/step\n","Epoch 14/70\n","46/46 - 31s - loss: 5.5072 - accuracy: 0.0657 - 31s/epoch - 679ms/step\n","Epoch 15/70\n","46/46 - 34s - loss: 5.4479 - accuracy: 0.0712 - 34s/epoch - 731ms/step\n","Epoch 16/70\n","46/46 - 31s - loss: 5.6052 - accuracy: 0.0698 - 31s/epoch - 683ms/step\n","Epoch 17/70\n","46/46 - 32s - loss: 5.3275 - accuracy: 0.0835 - 32s/epoch - 686ms/step\n","Epoch 18/70\n","46/46 - 33s - loss: 5.2597 - accuracy: 0.0856 - 33s/epoch - 722ms/step\n","Epoch 19/70\n","46/46 - 31s - loss: 5.2003 - accuracy: 0.0924 - 31s/epoch - 682ms/step\n","Epoch 20/70\n","46/46 - 31s - loss: 5.1442 - accuracy: 0.0951 - 31s/epoch - 678ms/step\n","Epoch 21/70\n","46/46 - 35s - loss: 5.0707 - accuracy: 0.0992 - 35s/epoch - 760ms/step\n","Epoch 22/70\n","46/46 - 32s - loss: 5.0066 - accuracy: 0.1027 - 32s/epoch - 698ms/step\n","Epoch 23/70\n","46/46 - 32s - loss: 4.9438 - accuracy: 0.1027 - 32s/epoch - 705ms/step\n","Epoch 24/70\n","46/46 - 32s - loss: 4.8846 - accuracy: 0.1081 - 32s/epoch - 705ms/step\n","Epoch 25/70\n","46/46 - 31s - loss: 4.8410 - accuracy: 0.1123 - 31s/epoch - 675ms/step\n","Epoch 26/70\n","46/46 - 31s - loss: 4.7619 - accuracy: 0.1184 - 31s/epoch - 681ms/step\n","Epoch 27/70\n","46/46 - 35s - loss: 4.7009 - accuracy: 0.1218 - 35s/epoch - 762ms/step\n","Epoch 28/70\n","46/46 - 32s - loss: 4.6606 - accuracy: 0.1218 - 32s/epoch - 688ms/step\n","Epoch 29/70\n","46/46 - 31s - loss: 4.5862 - accuracy: 0.1314 - 31s/epoch - 675ms/step\n","Epoch 30/70\n","46/46 - 31s - loss: 4.5289 - accuracy: 0.1362 - 31s/epoch - 679ms/step\n","Epoch 31/70\n","46/46 - 31s - loss: 4.4692 - accuracy: 0.1396 - 31s/epoch - 680ms/step\n","Epoch 32/70\n","46/46 - 31s - loss: 4.4284 - accuracy: 0.1499 - 31s/epoch - 673ms/step\n","Epoch 33/70\n","46/46 - 33s - loss: 4.3563 - accuracy: 0.1520 - 33s/epoch - 717ms/step\n","Epoch 34/70\n","46/46 - 31s - loss: 4.2964 - accuracy: 0.1588 - 31s/epoch - 666ms/step\n","Epoch 35/70\n","46/46 - 33s - loss: 4.2416 - accuracy: 0.1643 - 33s/epoch - 715ms/step\n","Epoch 36/70\n","46/46 - 32s - loss: 4.1821 - accuracy: 0.1739 - 32s/epoch - 701ms/step\n","Epoch 37/70\n","46/46 - 32s - loss: 4.1268 - accuracy: 0.1793 - 32s/epoch - 695ms/step\n","Epoch 38/70\n","46/46 - 32s - loss: 4.0707 - accuracy: 0.1930 - 32s/epoch - 703ms/step\n","Epoch 39/70\n","46/46 - 35s - loss: 4.0138 - accuracy: 0.1937 - 35s/epoch - 755ms/step\n","Epoch 40/70\n","46/46 - 34s - loss: 3.9606 - accuracy: 0.2115 - 34s/epoch - 737ms/step\n","Epoch 41/70\n","46/46 - 31s - loss: 3.9093 - accuracy: 0.2129 - 31s/epoch - 681ms/step\n","Epoch 42/70\n","46/46 - 32s - loss: 3.8583 - accuracy: 0.2245 - 32s/epoch - 687ms/step\n","Epoch 43/70\n","46/46 - 31s - loss: 3.8349 - accuracy: 0.2259 - 31s/epoch - 677ms/step\n","Epoch 44/70\n","46/46 - 32s - loss: 3.7998 - accuracy: 0.2355 - 32s/epoch - 690ms/step\n","Epoch 45/70\n","46/46 - 37s - loss: 3.7158 - accuracy: 0.2526 - 37s/epoch - 799ms/step\n","Epoch 46/70\n","46/46 - 30s - loss: 3.6570 - accuracy: 0.2676 - 30s/epoch - 663ms/step\n","Epoch 47/70\n","46/46 - 32s - loss: 3.6002 - accuracy: 0.2704 - 32s/epoch - 691ms/step\n","Epoch 48/70\n","46/46 - 32s - loss: 3.5499 - accuracy: 0.2827 - 32s/epoch - 689ms/step\n","Epoch 49/70\n","46/46 - 32s - loss: 3.4979 - accuracy: 0.2943 - 32s/epoch - 688ms/step\n","Epoch 50/70\n","46/46 - 32s - loss: 3.4632 - accuracy: 0.3012 - 32s/epoch - 701ms/step\n","Epoch 51/70\n","46/46 - 35s - loss: 3.4131 - accuracy: 0.3107 - 35s/epoch - 759ms/step\n","Epoch 52/70\n","46/46 - 31s - loss: 3.3560 - accuracy: 0.3217 - 31s/epoch - 675ms/step\n","Epoch 53/70\n","46/46 - 31s - loss: 3.3108 - accuracy: 0.3251 - 31s/epoch - 674ms/step\n","Epoch 54/70\n","46/46 - 31s - loss: 3.2612 - accuracy: 0.3504 - 31s/epoch - 684ms/step\n","Epoch 55/70\n","46/46 - 32s - loss: 3.2137 - accuracy: 0.3504 - 32s/epoch - 689ms/step\n","Epoch 56/70\n","46/46 - 34s - loss: 3.1614 - accuracy: 0.3689 - 34s/epoch - 745ms/step\n","Epoch 57/70\n","46/46 - 34s - loss: 3.1222 - accuracy: 0.3765 - 34s/epoch - 734ms/step\n","Epoch 58/70\n","46/46 - 32s - loss: 3.0779 - accuracy: 0.3840 - 32s/epoch - 704ms/step\n","Epoch 59/70\n","46/46 - 31s - loss: 3.0777 - accuracy: 0.3778 - 31s/epoch - 685ms/step\n","Epoch 60/70\n","46/46 - 33s - loss: 3.0272 - accuracy: 0.3984 - 33s/epoch - 713ms/step\n","Epoch 61/70\n","46/46 - 33s - loss: 2.9610 - accuracy: 0.4107 - 33s/epoch - 711ms/step\n","Epoch 62/70\n","46/46 - 32s - loss: 2.9070 - accuracy: 0.4237 - 32s/epoch - 694ms/step\n","Epoch 63/70\n","46/46 - 31s - loss: 2.8581 - accuracy: 0.4428 - 31s/epoch - 678ms/step\n","Epoch 64/70\n","46/46 - 33s - loss: 2.8117 - accuracy: 0.4463 - 33s/epoch - 726ms/step\n","Epoch 65/70\n","46/46 - 33s - loss: 2.7669 - accuracy: 0.4517 - 33s/epoch - 709ms/step\n","Epoch 66/70\n","Epoch 67/70\n","46/46 - 31s - loss: 2.6794 - accuracy: 0.4784 - 31s/epoch - 679ms/step\n","Epoch 68/70\n","46/46 - 32s - loss: 2.6377 - accuracy: 0.4901 - 32s/epoch - 694ms/step\n","Epoch 69/70\n","46/46 - 30s - loss: 2.5969 - accuracy: 0.4894 - 30s/epoch - 646ms/step\n","Epoch 70/70\n","46/46 - 33s - loss: 2.5533 - accuracy: 0.5079 - 33s/epoch - 722ms/step\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7ff85c6d7dc0>"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["Good = df.loc[df['rating_review']== 5 ]\n","Good = Good['review_full'][:10]\n","Good = Good.values\n","\n","def repreprocessing(raw_sentence):\n","    preproceseed_sentence = raw_sentence.encode(\"utf8\").decode(\"ascii\",'ignore')\n","    # 구두점 제거와 동시에 소문자화\n","    return ''.join(word for word in preproceseed_sentence if word not in punctuation).lower()\n","\n","Good_s = [repreprocessing(x) for x in Good]\n","\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(Good_s)\n","vocab_size = len(tokenizer.word_index) + 1\n","print('단어 집합의 크기 : %d' % vocab_size)\n","\n","sequences = list()\n","for line in Good_s: # 줄바꿈 문자를 기준으로 문장 토큰화\n","    encoded = tokenizer.texts_to_sequences([line])[0]\n","    for i in range(1, len(encoded)):\n","        sequence = encoded[:i+1]\n","        sequences.append(sequence)\n","\n","print('학습에 사용할 샘플의 개수: %d' % len(sequences))\n","\n","max_len = max(len(l) for l in sequences) # 모든 샘플에서 길이가 가장 긴 샘플의 길이 출력\n","print('샘플의 최대 길이 : {}'.format(max_len))\n","\n","sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')\n","sequences = np.array(sequences)\n","X = sequences[:,:-1]\n","y = sequences[:,-1]\n","y = to_categorical(y, num_classes=vocab_size)\n","\n","embedding_dim = 10\n","hidden_units = 32\n","\n","model = Sequential()\n","model.add(Embedding(vocab_size, embedding_dim))\n","model.add(SimpleRNN(hidden_units))\n","model.add(Dense(vocab_size, activation='softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.fit(X, y, epochs=70,batch_size=32, verbose=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rdZCmv6vNzKk","outputId":"1919381a-b046-44f6-d3c3-3214ab9157fd"},"outputs":[{"data":{"text/plain":["(1461, 634)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["X.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lMq-sRLz9TFh"},"outputs":[],"source":["def sentence_generation(model, tokenizer, current_word, n): # 모델, 토크나이저, 현재 단어, 반복할 횟수\n","    init_word = current_word\n","    sentence = ''\n","\n","    # n번 반복\n","    for _ in range(n):\n","        # 현재 단어에 대한 정수 인코딩과 패딩\n","        encoded = tokenizer.texts_to_sequences([current_word])[0]\n","        encoded = pad_sequences([encoded], maxlen=5, padding='pre')\n","        # 입력한 X(현재 단어)에 대해서 Y를 예측하고 Y(예측한 단어)를 result에 저장.\n","        result = model.predict(encoded, verbose=0)\n","        result = np.argmax(result, axis=1)\n","\n","        for word, index in tokenizer.word_index.items():\n","            # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면 break\n","            if index == result:\n","                break\n","\n","        # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n","        current_word = current_word + ' '  + word\n","\n","        # 예측 단어를 문장에 저장\n","        sentence = sentence + ' ' + word\n","\n","    sentence = init_word + sentence\n","    return sentence"]},{"cell_type":"markdown","metadata":{"id":"6vj4s0E9lZna"},"source":["- 위의 코드는 좋은 리뷰를 모델에게 학습시키는 코드이다\n","- 학습시킨 모델을 이용해서 자연어를 생성한다"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kow75sPMxBq3","outputId":"fb53de6f-031c-4540-ca49-c7d286f91548"},"outputs":[{"name":"stdout","output_type":"stream","text":["hotel is very good with it up motifs and the meal and its immediately recognizable though\n","This hotel the best of the best adores noodle soups and all bite and hot and complimented a little but to is\n","First visit jamun and very crispy and hot and assorted good with it had food the best\n"]}],"source":["print(sentence_generation(model, tokenizer, 'hotel', 15))\n","print(sentence_generation(model, tokenizer, 'This hotel', 20))\n","print(sentence_generation(model, tokenizer, 'First visit', 15))"]},{"cell_type":"markdown","metadata":{"id":"iJnXQil5mnBI"},"source":["- 시작 단어를 hotel, This hotel, First visit과 같이 주었는데 어느 정도 좋은 리뷰들을 잘 조합해내는 것을 볼 수 있다\n","- epoch를 70으로 batch size는 32로 학습시키는데 무려 40분이 소요되었다\n","- 만약 epoch를 더 늘리고, batch size를 줄여서 학습 시키면 더 연관성 있는 리뷰를 생성할 것이라고 예상할 수 있다"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8WkDqSV2Z9Gb","outputId":"db1b763d-f772-405f-e6a0-828a3e666b38"},"outputs":[{"name":"stdout","output_type":"stream","text":["단어 집합의 크기 : 757\n","학습에 사용할 샘플의 개수: 2106\n","샘플의 최대 길이 : 382\n","Epoch 1/70\n","66/66 - 42s - loss: 6.4372 - accuracy: 0.0171 - 42s/epoch - 642ms/step\n","Epoch 2/70\n","66/66 - 38s - loss: 5.9205 - accuracy: 0.0484 - 38s/epoch - 579ms/step\n","Epoch 3/70\n","66/66 - 35s - loss: 5.8436 - accuracy: 0.0484 - 35s/epoch - 528ms/step\n","Epoch 4/70\n","66/66 - 33s - loss: 5.8329 - accuracy: 0.0484 - 33s/epoch - 495ms/step\n","Epoch 5/70\n","66/66 - 31s - loss: 5.8290 - accuracy: 0.0484 - 31s/epoch - 467ms/step\n","Epoch 6/70\n","66/66 - 30s - loss: 5.8243 - accuracy: 0.0484 - 30s/epoch - 459ms/step\n","Epoch 7/70\n","66/66 - 30s - loss: 5.8191 - accuracy: 0.0484 - 30s/epoch - 460ms/step\n","Epoch 8/70\n"]}],"source":["# 부정적리뷰\n","Bad = df.loc[df['rating_review']== 1 ]\n","Bad = Bad['review_full'][20:40]\n","Bad = Bad.values\n","\n","def repreprocessing(raw_sentence):\n","    preproceseed_sentence = raw_sentence.encode(\"utf8\").decode(\"ascii\",'ignore')\n","    # 구두점 제거와 동시에 소문자화\n","    return ''.join(word for word in preproceseed_sentence if word not in punctuation).lower()\n","\n","Bad_s = [repreprocessing(x) for x in Bad]\n","\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(Bad_s)\n","vocab_size = len(tokenizer.word_index) + 1\n","print('단어 집합의 크기 : %d' % vocab_size)\n","\n","sequences_b = list()\n","for line in Bad_s: # 줄바꿈 문자를 기준으로 문장 토큰화\n","    encoded = tokenizer.texts_to_sequences([line])[0]\n","    for i in range(1, len(encoded)):\n","        sequence = encoded[:i+1]\n","        sequences_b.append(sequence)\n","\n","print('학습에 사용할 샘플의 개수: %d' % len(sequences_b))\n","\n","max_len = max(len(l) for l in sequences_b) # 모든 샘플에서 길이가 가장 긴 샘플의 길이 출력\n","print('샘플의 최대 길이 : {}'.format(max_len))\n","\n","sequences_b = pad_sequences(sequences_b, maxlen=max_len, padding='pre')\n","sequences_b = np.array(sequences_b)\n","X_b = sequences_b[:,:-1]\n","y_b = sequences_b[:,-1]\n","y_b = to_categorical(y_b, num_classes=vocab_size)\n","\n","embedding_dim = 10\n","hidden_units = 32\n","\n","model = Sequential()\n","model.add(Embedding(vocab_size, embedding_dim))\n","model.add(SimpleRNN(hidden_units))\n","model.add(Dense(vocab_size, activation='softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.fit(X_b, y_b, epochs=30,batch_size=32, verbose=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"upyK5awIbysU","outputId":"1a004892-e5cf-4827-f256-6606c55197a5"},"outputs":[{"name":"stdout","output_type":"stream","text":["hotel my mutton pm me may hamper a few times and half hours that the oven\n","this hotel that a be pm from may hamper dont restaurant and found dont embarrassing to send behave customer when and were\n","visit that a few minutes of were food i am my manager offered in 20 minutes\n","it the mutton quality bit high market dimension solution ltd reads my ltd offered in a\n","the mutton i sold may hamper a few minutes of were food i am my manager\n"]}],"source":["print(sentence_generation(model, tokenizer, 'hotel', 15))\n","print(sentence_generation(model, tokenizer, 'this hotel', 20))\n","print(sentence_generation(model, tokenizer, 'visit', 15))\n","print(sentence_generation(model, tokenizer, 'it', 15))\n","print(sentence_generation(model, tokenizer, 'the', 15))"]},{"cell_type":"markdown","metadata":{"id":"By0cqfJtm4r-"},"source":["### 결론\n","- 시작 단어를 hotel, this hotel, visit, it, the 와 같이 주었는데 어느 정도 나쁜 리뷰들을 잘 조합해내는 것을 볼 수 있다\n","- epoch를 30으로 batch size는 32로 학습시키는데 무려 20분이 소요되었다\n","- 만약 epoch를 더 늘리고, batch size를 줄여서 학습 시키면 더 연관성 있는 리뷰를 생성할 것이라고 예상할 수 있다"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":0}